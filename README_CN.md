![img1](https://github.com/zhenglinpan/Awesome-Animation-Research/blob/master/assets/teaser.gif)

[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/amirhossein-kz/Awesome-Diffusion-Models-in-Medical-Imaging) 
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)
[![Teaser](https://img.shields.io/badge/Teaser_by-寝国-pink)](https://space.bilibili.com/177312952?spm_id_from=333.337.0.0)
<p align="left">
   <a href="https://github.com/zhenglinpan/Awesome-Animation-Research/blob/master/README.md">ENGLISH</a> | 简体中文
</p>

# Awesome Animation Research 🎥📚

本repo收集了一批关于**🎞️赛璐珞动画/🎞️卡通动画**的各种研究、数据集及其相关资源。

💁‍♀️**在这里你可以找到:** 有可能帮助到动画业界的技术论文、数据集、repo等。例如：中割生成、原画上色等。

🤷‍♀️**这个repo不包括:** 广义的Anime研究。例如：动漫风格滤镜、动漫图像超分、动漫人物生成等。如果你对广义的Anime研究感兴趣，请移步[AwesomeAnimeResearch](https://github.com/SerialLain3170/AwesomeAnimeResearch).


****

🙇‍♀️赛璐珞动画制作非常不易、需要大量动画人一帧帧地手绘，这会花费大量的时间和精力。计算机视觉技术也许正在改变这一现状，有不少的研究者正在尝试利用这一技术辅助动画制作中的某些环节，例如自动中割、自动上色等。

目前这个repo列表目前还很短，因为动画的计算机视觉研究是一个相对新兴且小众的领域，我们期待更多的研究者（也包括你）一起为这个领域的发展做出贡献。

本repo会持续关注最新的研究成果，欢迎关注! 🌟

## 新文章
<!-- [<span style="color:red">*new</span>]  -->

🚩【数据集】**Sakuga-42M Dataset: Scaling Up Cartoon Research** \
*Zhenglin Pan, Yu Zhu, Yuxuan Mu* \
[13 May., 2024] [arXiv, 2024] \
[[paper](https://arxiv.org/abs/2405.07425)] | [webpage] | [demo] | [[repo](https://github.com/zhenglinpan/SakugaDataset)] | [[dataset](https://github.com/zhenglinpan/SakugaDataset)]

🚩【中割】**Joint Stroke Tracing and Correspondence for 2D Animation** \
*Haoran Mo, Chengying Gao, Ruomei Wang*\
[9 Apr., 2024] [SIGGRAPH, 2024] \
[[paper](https://dl.acm.org/doi/10.1145/3649890)] | [[webpage](https://markmohr.github.io/JoSTC/)] | [demo] | [[repo](https://github.com/MarkMoHR/JoSTC)] | [dataset]

🚩【上色】**Learning Inclusion Matching for Animation Paint Bucket Colorization** \
*Yuekun Dai, Shangchen Zhou, Qinyue Li, Chongyi Li, Chen Change Loy*\
[2024] [CVPR, 2024] \
[[paper](https://arxiv.org/abs/2403.18342)] | [[webpage](https://ykdai.github.io/projects/InclusionMatching)] | [[demo](https://www.youtube.com/watch?v=nNnPUItGvSo&ab_channel=YuekunDai)] | [[repo](https://github.com/ykdai/BasicPBC)] | [[dataset](https://github.com/ykdai/BasicPBC/tree/main/dataset)]

## 数据集

**Sakuga-42M Dataset: Scaling Up Cartoon Research** \
*Zhenglin Pan, Yu Zhu, Yuxuan Mu* \
[13 May., 2024] [arXiv, 2024] \
[[paper](https://arxiv.org/abs/2405.07425)] | [webpage] | [demo] | [[repo](https://github.com/zhenglinpan/SakugaDataset)] | [[dataset](https://github.com/zhenglinpan/SakugaDataset)]

**AnimeRun: 2D Animation Visual Correspondence from Open Source 3D Movies** \
*Li Siyao, Yuhang Li, Bo Li, Chao Dong, Ziwei Liu, Chen Change Loy* \
[10 Nov., 2022] [arXiv, 2022] \
[[paper](https://arxiv.org/abs/2211.05709)] | [[webpage](https://lisiyao21.github.io/projects/AnimeRun)] | [demo] | [[repo](https://github.com/lisiyao21/AnimeRun)] | [[dataset](https://lisiyao21.github.io/projects/AnimeRun)]


## 上色

**Learning Inclusion Matching for Animation Paint Bucket Colorization** \
*Yuekun Dai, Shangchen Zhou, Qinyue Li, Chongyi Li, Chen Change Loy*\
[2024] [CVPR, 2024] \
[[paper](https://arxiv.org/abs/2403.18342)] | [[webpage](https://ykdai.github.io/projects/InclusionMatching)] | [[demo](https://www.youtube.com/watch?v=nNnPUItGvSo&ab_channel=YuekunDai)] | [[repo](https://github.com/ykdai/BasicPBC)] | [[dataset](https://github.com/ykdai/BasicPBC/tree/main/dataset)]

**Coloring anime line art videos with transformation region enhancement network** \
*Ning Wang, Muyao Niu, Zhi Dou, Zhihui Wang, Zhiyong Wang, Zhaoyan Ming, Bin Liu, Haojie Li*\
[Sep., 2023] [Elsevier, 2023] \
[[paper](https://www.sciencedirect.com/science/article/abs/pii/S0031320323002625)] | [webpage] | [demo] | [repo] | [dataset]

**SketchBetween: Video-to-Video Synthesis for Sprite Animation via Sketches** \
*Dagmar Lukka Loftsdóttir, Matthew Guzdial*\
[1 Sep., 2022] [ECCV, 2022] \
[[paper](https://arxiv.org/abs/2209.00185)] | [webpage] | [demo] | [[repo](https://github.com/ribombee/SketchBetween)] | [dataset]


**Animation Line Art Colorization Based on Optical Flow Method** \
*Yifeng Yu, Jiangbo Qian, Chong Wang, Yihong Dong, Baisong Liu*\
[27 Aug., 2022] [SSNR, 2022] \
[[paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4202289)] | [webpage] | [demo] | [repo] | [dataset]

**The Animation Transformer: Visual Correspondence via Segment Matching** \
*Evan Casey, Víctor Pérez, Zhuoru Li, Harry Teitelman, Nick Boyajian, Tim Pulver, Mike Manh, William Grisaitis*\
[6 Sep., 2021] [arXiv, 2021] \
[[paper](https://arxiv.org/abs/2109.02614)] | [webpage] | [[demo](https://cadmium.app/)] | [repo] | [dataset]

**Artist-Guided Semiautomatic Animation Colorization** \
*Harrish Thasarathan, Mehran Ebrahimi* \
[22 Jun., 2020] [arXiv, 2020] \
[[paper](https://arxiv.org/abs/2006.13717)] | [webpage] | [demo] | [repo] | [dataset]

**Line Art Correlation Matching Feature Transfer Network for Automatic Animation Colorization** \
*Zhang Qian, Wang Bo, Wen Wei, Li Hai, Liu Jun Hui* \
[14 Apr., 2020] [arXiv, 2020] \
[[paper](https://arxiv.org/abs/2004.06718)] | [webpage] | [demo] | [repo] | [dataset]

**Deep Line Art Video Colorization with a Few References** \
*Min Shi, Jia-Qi Zhang, Shu-Yu Chen, Lin Gao, Yu-Kun Lai, Fang-Lue Zhang* \
[24 Mar., 2020] [arXiv, 2020] \
[[paper](https://arxiv.org/abs/2003.10685)] | [webpage] | [demo] | [repo] | [dataset]

**Automatic Temporally Coherent Video Colorization** \
*Harrish Thasarathan, Kamyar Nazeri, Mehran Ebrahimi* \
[[paper](https://arxiv.org/abs/1904.09527)] | [webpage] | [demo] | [[repo](https://github.com/Harry-Thasarathan/TCVC)] | [dataset]






## 中割/插帧

**Joint Stroke Tracing and Correspondence for 2D Animation** \
*Haoran Mo, Chengying Gao, Ruomei Wang*\
[9 Apr., 2024] [SIGGRAPH, 2024] \
[[paper](https://dl.acm.org/doi/10.1145/3649890)] | [[webpage](https://markmohr.github.io/JoSTC/)] | [demo] | [[repo](https://github.com/MarkMoHR/JoSTC)] | [dataset]

**Deep Geometrized Cartoon Line Inbetweening** \
*Li Siyao, Tianpei Gu, Weiye Xiao, Henghui Ding, Ziwei Liu, Chen Change Loy*\
[Nov., 2023] [ICCV 2023] \
[[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Siyao_Deep_Geometrized_Cartoon_Line_Inbetweening_ICCV_2023_paper.html)] | [webpage] | [[demo](https://www.youtube.com/watch?v=iUF-LsqFKpI&ab_channel=SiyaoLi)] | [[repo](https://github.com/lisiyao21/AnimeInbet)] | [[dataset](https://drive.google.com/file/d/1SNRGajIECxNwRp6ZJ0IlY7AEl2mRm2DR/view)]


**Exploring inbetween charts with trajectory-guided sliders for cutout animation** \
*T Fukusato, A Maejima, T Igarashi, T Yotsukura*\
[1 Sep., 2023] [MTA 2023] \
[[paper](https://link.springer.com/article/10.1007/s11042-023-17354-x)]

**Enhanced Deep Animation Video Interpolation** \
*Wang Shen, Cheng Ming, Wenbo Bao, Guangtao Zhai, Li Chen, Zhiyong Gao*\
[25 Jun., 2022] [arXiv, 2022] \
[[paper](https://arxiv.org/abs/2206.12657)]

**Improving the Perceptual Quality of 2D Animation Interpolation** \
*Shuhong Chen, Matthias Zwicker*\
[24 Nov., 2021] [arXiv, 2021] \
[[paper](https://arxiv.org/abs/2111.12792)]

**Deep Animation Video Interpolation in the Wild** \
*Li Siyao, Shiyu Zhao, Weijiang Yu, Wenxiu Sun, Dimitris N. Metaxas, Chen Change Loy, Ziwei Liu*\
[6 Apr., 2021] [arXiv, 2021] \
[[paper](https://arxiv.org/abs/2104.02495)] | [[project](https://github.com/lisiyao21/AnimeInterp/)] | [[dataset](https://github.com/lisiyao21/AnimeInterp/)]

**Deep Sketch-guided Cartoon Video Inbetweening** \
*Xiaoyu Li, Bo Zhang, Jing Liao, Pedro V. Sander*\
[10 Aug., 2020] [arXiv, 2020] \
[[paper](https://arxiv.org/abs/2008.04149)] | [webpage] | [demo] | [repo] | [dataset]

**Optical Flow Based Line Drawing Frame Interpolation Using Distance Transform to Support Inbetweenings** \
*Rei Narita, Keigo Hirakawa, Kiyoharu Aizawa*\
[26 Aug., 2019] [IEEE, 2019] \
[[paper](https://ieeexplore.ieee.org/document/8803506)] | [webpage] | [demo] | [repo] | [dataset]

**DiLight: Digital light table – Inbetweening for 2D animations using guidelines** \
*Leonardo Carvalho, Ricardo Marroquim, Emilio Vital Brazil*\
[Jun., 2017] [Elsevier, 2017] \
[[paper](https://www.sciencedirect.com/science/article/abs/pii/S0097849317300390)] | [webpage] | [demo] | [repo] | [dataset]




## 编辑

**Re:Draw -- Context Aware Translation as a Controllable Method for Artistic Production** \
*Joao Liborio Cardoso, Francesco Banterle, Paolo Cignoni, Michael Wimmer*\
[Jan., 2024] [*TBA 2024] \
[[paper](https://arxiv.org/abs/2401.03499)] | [webpage] | [demo] | [repo] | [dataset]

**Sprite-from-Sprite: Cartoon Animation Decomposition with Self-supervised Sprite Estimation** \
*Lvmin Zhang, Tien-Tsin Wong, Yuxin Liu*\
[Nov., 2022] [ACM 2022] \
[[paper](https://dl.acm.org/doi/pdf/10.1145/3550454.3555439)] | [webpage] | [demo] | [[repo](https://lllyasviel.github.io/GitPageToonDecompose/)] | [dataset]

**Toonsynth: example-based synthesis of hand-colored cartoon animations** \
*M Dvorožnák, W Li, VG Kim, D Sýkora*\
[Jul., 2018] [TOG 2018] \
[[paper](https://dl.acm.org/doi/abs/10.1145/3197517.3201326)] | [webpage] | [demo] | [repo] | [dataset]

## 跟踪/匹配

**Globally Optimal Toon Tracking** \
*Haichao Zhu, Xueting Liu, Tien-Tsin Wong, Pheng-Ann Heng* \
[11 Jul., 2016] [TOG, 2016] \
[[paper](https://dl.acm.org/doi/10.1145/2897824.2925872)] | [webpage] | [demo] | [repo] | [dataset]

## 分割

**Stereoscopizing Cel Animations** \
*Xueting Liu, Xiangyu Mao, Xuan Yang, Linling Zhang, Tien-Tsin Wong* \
[11 Jul., 2016] [ACM, 2013] \
[[paper](https://dl.acm.org/doi/abs/10.1145/2508363.2508396)] | [webpage] | [demo] | [repo] | [dataset]

## 如何Contribute 
我们鼓励动画爱好者、研究者通过添加相关论文、文章和各类资源的形式为本资料库做出贡献。您的贡献将有助于为任何对动画研究感兴趣的人提供有价值的参考。

只需 fork 本资源库，进行添加或改进，并pull request即可。

---

<div align="center">
    <em>希望动画因我们而更好.</em>
</div>

<div align="center">
   <img src="https://github.com/zhenglinpan/Awesome-Animation-Research/blob/master/assets/Hatsune_Miku_@illufinch.png" width="40" >
</div>
<p align="center"><sub><i>图标 by Twitter</i>©illufinch</sub></p>
