![img1](https://github.com/zhenglinpan/Awesome-Animation-Research/blob/master/assets/teaser.gif)

[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/amirhossein-kz/Awesome-Diffusion-Models-in-Medical-Imaging) 
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)
[![Teaser](https://img.shields.io/badge/Teaser_by-寝国-pink)](https://space.bilibili.com/177312952?spm_id_from=333.337.0.0)
<p align="left">
   <a href="https://github.com/zhenglinpan/FillLineGaps/blob/master/README_CN.md">ENGLISH</a> | 简体中文
</p>

# Awesome Animation Research 🎥📚

本repo收集了一批关于**卡通动画/赛璐珞动画**的各种研究、数据集及其相关资源。

**在这里你可以找到:** 有可能帮助到动画业界的技术论文、数据集、repo等。例如：中割生成、原画上色等。

**这个repo不包括:** 广义的Anime研究。例如：动漫风格滤镜、动漫图像超分、动漫人物生成等。如果你对广义的Anime研究感兴趣，请移步[AwesomeAnimeResearch](https://github.com/SerialLain3170/AwesomeAnimeResearch).


****

赛璐珞动画制作非常不易、需要大量动画人一帧帧地手绘，这会花费大量的时间和精力。计算机视觉技术也许正在改变这一现状，有不少的研究者正在尝试利用这一技术辅助动画制作中的某些环节，例如自动中割、自动上色等。

目前这个repo列表目前还很短，因为动画的计算机视觉研究是一个相对新兴且小众的领域，我们期待更多的研究者（也包括你）一起为这个领域的发展做出贡献。

本repo会持续关注最新的研究成果，欢迎关注! 🌟

## 新文章
<!-- [<span style="color:red">*new</span>]  -->

🚩 **Re:Draw -- Context Aware Translation as a Controllable Method for Artistic Production** \
*Joao Liborio Cardoso, Francesco Banterle, Paolo Cignoni, Michael Wimmer*\
[Jan., 2024] [*TBA 2024] \
[[paper](https://arxiv.org/abs/2401.03499)]

🚩 **Exploring inbetween charts with trajectory-guided sliders for cutout animation** \
*T Fukusato, A Maejima, T Igarashi, T Yotsukura*\
[1 Sep., 2023] [MTA 2023] \
[[paper](https://link.springer.com/article/10.1007/s11042-023-17354-x)]

🚩 **Deep Geometrized Cartoon Line Inbetweening** \
*Li Siyao, Tianpei Gu, Weiye Xiao, Henghui Ding, Ziwei Liu, Chen Change Loy*\
[Nov., 2023] [ICCV 2023] \
[[paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Siyao_Deep_Geometrized_Cartoon_Line_Inbetweening_ICCV_2023_paper.pdf)] | [[project](https://github.com/lisiyao21/AnimeInbet)] | [[dataset](https://github.com/lisiyao21/AnimeInbet)]


## 数据集

**AnimeRun: 2D Animation Visual Correspondence from Open Source 3D Movies** \
*Li Siyao, Yuhang Li, Bo Li, Chao Dong, Ziwei Liu, Chen Change Loy* \
[10 Nov., 2022] [arXiv, 2022] \
[[Paper](https://arxiv.org/abs/2211.05709)] | [[project](https://lisiyao21.github.io/projects/AnimeRun)] | [[dataset](https://lisiyao21.github.io/projects/AnimeRun)]


## 上色

**Coloring anime line art videos with transformation region enhancement network** \
*Ning Wang, Muyao Niu, Zhi Dou, Zhihui Wang, Zhiyong Wang, Zhaoyan Ming, Bin Liu, Haojie Li*\
[Sep., 2023] [Elsevier, 2023] \
[[Paper](https://www.sciencedirect.com/science/article/abs/pii/S0031320323002625)]

**Animation Line Art Colorization Based on Optical Flow Method** \
*Yifeng Yu, Jiangbo Qian, Chong Wang, Yihong Dong, Baisong Liu*\
[27 Aug., 2022] [SSNR, 2022] \
[[Paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4202289)]

**The Animation Transformer: Visual Correspondence via Segment Matching** \
*Evan Casey, Víctor Pérez, Zhuoru Li, Harry Teitelman, Nick Boyajian, Tim Pulver, Mike Manh, William Grisaitis*\
[6 Sep., 2021] [arXiv, 2021] \
[[Paper](https://arxiv.org/abs/2109.02614)] | [[Demo](https://cadmium.app/)]

**Artist-Guided Semiautomatic Animation Colorization** \
*Harrish Thasarathan, Mehran Ebrahimi* \
[22 Jun., 2020] [arXiv, 2020] \
[[Paper](https://arxiv.org/abs/2006.13717)]

**Line Art Correlation Matching Feature Transfer Network for Automatic Animation Colorization** \
*Zhang Qian, Wang Bo, Wen Wei, Li Hai, Liu Jun Hui* \
[14 Apr., 2020] [arXiv, 2020] \
[[Paper](https://arxiv.org/abs/2004.06718)]

**Deep Line Art Video Colorization with a Few References** \
*Min Shi, Jia-Qi Zhang, Shu-Yu Chen, Lin Gao, Yu-Kun Lai, Fang-Lue Zhang* \
[24 Mar., 2020] [arXiv, 2020] \
[[Paper](https://arxiv.org/abs/2003.10685)]

**Automatic Temporally Coherent Video Colorization** \
*Harrish Thasarathan, Kamyar Nazeri, Mehran Ebrahimi* \
[21 Apr., 2019] [arXiv, 2019] \
[[Paper](https://arxiv.org/abs/1904.09527)] | [[project](https://github.com/Harry-Thasarathan/TCVC)]






## 中割/插帧

**Deep Geometrized Cartoon Line Inbetweening** \
*Li Siyao, Tianpei Gu, Weiye Xiao, Henghui Ding, Ziwei Liu, Chen Change Loy*\
[Nov., 2023] [ICCV 2023] \
[[paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Siyao_Deep_Geometrized_Cartoon_Line_Inbetweening_ICCV_2023_paper.pdf)] | [[project](https://github.com/lisiyao21/AnimeInbet)] | [[dataset](https://github.com/lisiyao21/AnimeInbet)]

**Exploring inbetween charts with trajectory-guided sliders for cutout animation** \
*T Fukusato, A Maejima, T Igarashi, T Yotsukura*\
[1 Sep., 2023] [MTA 2023] \
[[paper](https://link.springer.com/article/10.1007/s11042-023-17354-x)]

**SketchBetween: Video-to-Video Synthesis for Sprite Animation via Sketches** \
*Dagmar Lukka Loftsdóttir, Matthew Guzdial*\
[1 Sep., 2022] [ECCV, 2022] \
[[paper](https://arxiv.org/abs/2209.00185)] | [[project](https://github.com/ribombee/SketchBetween)]

**Enhanced Deep Animation Video Interpolation** \
*Wang Shen, Cheng Ming, Wenbo Bao, Guangtao Zhai, Li Chen, Zhiyong Gao*\
[25 Jun., 2022] [arXiv, 2022] \
[[paper](https://arxiv.org/abs/2206.12657)]

**Improving the Perceptual Quality of 2D Animation Interpolation** \
*Shuhong Chen, Matthias Zwicker*\
[24 Nov., 2021] [arXiv, 2021] \
[[paper](https://arxiv.org/abs/2111.12792)]

**Deep Animation Video Interpolation in the Wild** \
*Li Siyao, Shiyu Zhao, Weijiang Yu, Wenxiu Sun, Dimitris N. Metaxas, Chen Change Loy, Ziwei Liu*\
[6 Apr., 2021] [arXiv, 2021] \
[[paper](https://arxiv.org/abs/2104.02495)] | [[project](https://github.com/lisiyao21/AnimeInterp/)] | [[dataset](https://github.com/lisiyao21/AnimeInterp/)]

**Deep Sketch-guided Cartoon Video Inbetweening** \
*Xiaoyu Li, Bo Zhang, Jing Liao, Pedro V. Sander*\
[10 Aug., 2020] [arXiv, 2020] \
[[paper](https://arxiv.org/abs/2008.04149)]

**Optical Flow Based Line Drawing Frame Interpolation Using Distance Transform to Support Inbetweenings** \
*Rei Narita, Keigo Hirakawa, Kiyoharu Aizawa*\
[26 Aug., 2019] [IEEE, 2019] \
[[paper](https://ieeexplore.ieee.org/document/8803506)]

**DiLight: Digital light table – Inbetweening for 2D animations using guidelines** \
*Leonardo Carvalho, Ricardo Marroquim, Emilio Vital Brazil*\
[Jun., 2017] [Elsevier, 2017] \
[[paper](https://www.sciencedirect.com/science/article/abs/pii/S0097849317300390)]



## 编辑

**Re:Draw -- Context Aware Translation as a Controllable Method for Artistic Production** \
*Joao Liborio Cardoso, Francesco Banterle, Paolo Cignoni, Michael Wimmer*\
[Jan., 2024] [*TBA 2024] \
[[paper](https://arxiv.org/abs/2401.03499)]

**Sprite-from-Sprite: Cartoon Animation Decomposition with Self-supervised Sprite Estimation** \
*Lvmin Zhang, Tien-Tsin Wong, Yuxin Liu*\
[Nov., 2022] [ACM 2022] \
[[paper](https://dl.acm.org/doi/pdf/10.1145/3550454.3555439)] | [[project](https://lllyasviel.github.io/GitPageToonDecompose/)]


## 跟踪/匹配

**Globally Optimal Toon Tracking** \
*Haichao Zhu, Xueting Liu, Tien-Tsin Wong, Pheng-Ann Heng* \
[11 Jul., 2016] [TOG, 2016] \
[[Paper](https://dl.acm.org/doi/10.1145/2897824.2925872)]

## 分割

**Stereoscopizing Cel Animations** \
*Xueting Liu, Xiangyu Mao, Xuan Yang, Linling Zhang, Tien-Tsin Wong* \
[11 Jul., 2016] [ACM, 2013] \
[[Paper](https://dl.acm.org/doi/abs/10.1145/2508363.2508396)]


## 如何Contribute 
我们鼓励动画爱好者、研究者通过添加相关论文、文章和各类资源的形式为本资料库做出贡献。您的贡献将有助于为任何对动画研究感兴趣的人提供有价值的参考。

只需 fork 本资源库，进行添加或改进，并pull request即可。