# <p align=center>`Awesome Animation Research`</p> # 


[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/amirhossein-kz/Awesome-Diffusion-Models-in-Medical-Imaging) 
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)

Welcome to the `Awesome-Animation-Research` repository! ðŸŽ¥ðŸ“š

This repository provides a curated collection of research, articles, and resources related to animation and its production, with a **special focus on video**.

**What will be included in this repo:** Papers related to animation(video-related) that could assist animation production. i.e. Inbetweening, Video Colorization, Tie-down cleaning. 

**What will NOT be included:** General Anime. i.e. Anime Style Transfer, Anime Image Enhancement, Anime Image generation. Please refer to [AwesomeAnimeResearch](https://github.com/SerialLain3170/AwesomeAnimeResearch) for more information.

## New Papers

[<span style="color:red">*new</span>] **Deep Geometrized Cartoon Line Inbetweening** \
*Li Siyao, Tianpei Gu, Weiye Xiao, Henghui Ding, Ziwei Liu, Chen Change Loy*\
[Nov., 2023] [ICCV 2023] \
[[paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Siyao_Deep_Geometrized_Cartoon_Line_Inbetweening_ICCV_2023_paper.pdf)] | [[project](https://github.com/lisiyao21/AnimeInbet)]

[<span style="color:red">*new</span>] **Coloring anime line art videos with transformation region enhancement network** \
*Ning Wang, Muyao Niu, Zhi Dou, Zhihui Wang, Zhiyong Wang, Zhaoyan Ming, Bin Liu, Haojie Li*\
[Sep., 2023] [Elsevier, 2023] \
[[Paper](https://www.sciencedirect.com/science/article/abs/pii/S0031320323002625)]

## Reviews & Surveys


## Datasets

**AnimeRun: 2D Animation Visual Correspondence from Open Source 3D Movies** \
*Li Siyao, Yuhang Li, Bo Li, Chao Dong, Ziwei Liu, Chen Change Loy* \
[10 Nov., 2022] [arXiv, 2022] \
[[Paper](https://arxiv.org/abs/2211.05709)] | [[project](https://lisiyao21.github.io/projects/AnimeRun)]






## Animation Colorization

**Coloring anime line art videos with transformation region enhancement network** \
*Ning Wang, Muyao Niu, Zhi Dou, Zhihui Wang, Zhiyong Wang, Zhaoyan Ming, Bin Liu, Haojie Li*\
[Sep., 2023] [Elsevier, 2023] \
[[Paper](https://www.sciencedirect.com/science/article/abs/pii/S0031320323002625)]

**Animation Line Art Colorization Based on Optical Flow Method** \
*Yifeng Yu, Jiangbo Qian, Chong Wang, Yihong Dong, Baisong Liu*\
[27 Aug., 2022] [SSNR, 2022] \
[[Paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4202289)]


**The Animation Transformer: Visual Correspondence via Segment Matching** \
*Evan Casey, VÃ­ctor PÃ©rez, Zhuoru Li, Harry Teitelman, Nick Boyajian, Tim Pulver, Mike Manh, William Grisaitis*\
[6 Sep., 2021] [arXiv, 2021] \
[[Paper](https://arxiv.org/abs/2109.02614)] | [[Demo](https://cadmium.app/)]

**Artist-Guided Semiautomatic Animation Colorization** \
*Harrish Thasarathan, Mehran Ebrahimi* \
[22 Jun., 2020] [arXiv, 2020] \
[[Paper](https://arxiv.org/abs/2006.13717)]

**Deep Line Art Video Colorization with a Few References** \
*Min Shi, Jia-Qi Zhang, Shu-Yu Chen, Lin Gao, Yu-Kun Lai, Fang-Lue Zhang* \
[24 Mar., 2020] [arXiv, 2020] \
[[Paper](https://arxiv.org/abs/2003.10685)]

**Line Art Correlation Matching Feature Transfer Network for Automatic Animation Colorization** \
*Zhang Qian, Wang Bo, Wen Wei, Li Hai, Liu Jun Hui* \
[14 Apr., 2020] [arXiv, 2020] \
[[Paper](https://arxiv.org/abs/2004.06718)]

**Automatic Temporally Coherent Video Colorization** \
*Harrish Thasarathan, Kamyar Nazeri, Mehran Ebrahimi* \
[21 Apr., 2019] [arXiv, 2019] \
[[Paper](https://arxiv.org/abs/1904.09527)] | [[project](https://github.com/Harry-Thasarathan/TCVC)]






## Animation Inbetweening & Interpolation

**Deep Geometrized Cartoon Line Inbetweening** \
*Li Siyao, Tianpei Gu, Weiye Xiao, Henghui Ding, Ziwei Liu, Chen Change Loy*\
[Nov., 2023] [ICCV 2023] \
[[paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Siyao_Deep_Geometrized_Cartoon_Line_Inbetweening_ICCV_2023_paper.pdf)] | [[project](https://github.com/lisiyao21/AnimeInbet)]

**Enhanced Deep Animation Video Interpolation** \
*Wang Shen, Cheng Ming, Wenbo Bao, Guangtao Zhai, Li Chen, Zhiyong Gao*\
[25 Jun., 2022] [arXiv, 2022] \
[[paper](https://arxiv.org/abs/2206.12657)]


**SketchBetween: Video-to-Video Synthesis for Sprite Animation via Sketches** \
*Dagmar Lukka LoftsdÃ³ttir, Matthew Guzdial*\
[1 Sep., 2022] [arXiv, 2022] \
[[paper](https://arxiv.org/abs/2209.00185)] | [[project](https://github.com/ribombee/SketchBetween)]

**Deep Sketch-guided Cartoon Video Inbetweening** \
*Xiaoyu Li, Bo Zhang, Jing Liao, Pedro V. Sander*\
[10 Aug., 2020] [arXiv, 2020] \
[[paper](https://arxiv.org/abs/2008.04149)]

**Optical Flow Based Line Drawing Frame Interpolation Using Distance Transform to Support Inbetweenings** \
*Rei Narita, Keigo Hirakawa, Kiyoharu Aizawa*\
[26 Aug., 2019] [IEEE, 2019] \
[[paper](https://ieeexplore.ieee.org/document/8803506)]

**DiLight: Digital light table â€“ Inbetweening for 2D animations using guidelines** \
*Leonardo Carvalho, Ricardo Marroquim, Emilio Vital Brazil*\
[Jun., 2017] [Elsevier, 2017] \
[[paper](https://www.sciencedirect.com/science/article/abs/pii/S0097849317300390)]


## Tie-down Cleanup

**Learning to Simplify: Fully Convolutional Networks for Rough Sketch Cleanup** \
*Edgar Simo-Serra, Satoshi Iizuka, Kazuma Sasaki, Hiroshi Ishikawa*\
[Jul., 2016] [ACM, 2016] \
[[paper](https://esslab.jp/~ess/publications/SimoSerraSIGGRAPH2016.pdf)]



## How to Contribute
We encourage animation enthusiasts, researchers, and scholars to contribute to this repository by adding relevant papers, articles, and resources. Your contributions will help build a valuable reference for anyone interested in the art and science of animation.

To contribute, simply fork this repository, make your additions or improvements, and submit a pull request. Please follow the contribution guidelines outlined in the repository's README file.