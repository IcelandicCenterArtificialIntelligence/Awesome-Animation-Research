# <p align=center>`Awesome Animation Research`</p> # 

[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/amirhossein-kz/Awesome-Diffusion-Models-in-Medical-Imaging) 
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)

# Awesome Animation Research ðŸŽ¥ðŸ“š

This repository provides a curated collection of dataset, research, and resources related to **animation(cartoon video)** specifically. 

**What You'll Find Here:** Papers/Dataset/Repo closely related to animation(cartoon video) that could potentially assist creating animation. e.g. Inbetweening, Video Colorization. 

**What's Not Included:** General Anime Research. i.e. Anime Style Transfer, Anime Image Enhancement, Anime Image generation. If you are interested in general anime research, please refer to [AwesomeAnimeResearch](https://github.com/SerialLain3170/AwesomeAnimeResearch).

****

Creating animation is time-consuming and often involves manual work. AI tools are changing this landscape. Researchers are tackling animation-specific challenges like inbetweening and frame-to-frame color propagation. 

You might notice the repo's list is currently short. Animation research is a relatively new and niche area, and we look forward to more researchers, including you, contributing to its growth.

The repo will keep track of the latest research. Feel free to follow and star ! ðŸŒŸ

## New Papers
<!-- [<span style="color:red">*new</span>]  -->

ðŸš© **Exploring inbetween charts with trajectory-guided sliders for cutout animation**
*T Fukusato, A Maejima, T Igarashi, T Yotsukura*\
[1 Sep., 2023] [MTA 2023] \
[[paper](https://link.springer.com/article/10.1007/s11042-023-17354-x)]

ðŸš© **Deep Geometrized Cartoon Line Inbetweening** \
*Li Siyao, Tianpei Gu, Weiye Xiao, Henghui Ding, Ziwei Liu, Chen Change Loy*\
[Nov., 2023] [ICCV 2023] \
[[paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Siyao_Deep_Geometrized_Cartoon_Line_Inbetweening_ICCV_2023_paper.pdf)] | [[project](https://github.com/lisiyao21/AnimeInbet)] | [[dataset](https://github.com/lisiyao21/AnimeInbet)]

ðŸš© **Coloring anime line art videos with transformation region enhancement network** \
*Ning Wang, Muyao Niu, Zhi Dou, Zhihui Wang, Zhiyong Wang, Zhaoyan Ming, Bin Liu, Haojie Li*\
[Sep., 2023] [Elsevier, 2023] \
[[Paper](https://www.sciencedirect.com/science/article/abs/pii/S0031320323002625)]


## Datasets

**AnimeRun: 2D Animation Visual Correspondence from Open Source 3D Movies** \
*Li Siyao, Yuhang Li, Bo Li, Chao Dong, Ziwei Liu, Chen Change Loy* \
[10 Nov., 2022] [arXiv, 2022] \
[[Paper](https://arxiv.org/abs/2211.05709)] | [[project](https://lisiyao21.github.io/projects/AnimeRun)] | [[dataset](https://lisiyao21.github.io/projects/AnimeRun)]






## Colorization

**Coloring anime line art videos with transformation region enhancement network** \
*Ning Wang, Muyao Niu, Zhi Dou, Zhihui Wang, Zhiyong Wang, Zhaoyan Ming, Bin Liu, Haojie Li*\
[Sep., 2023] [Elsevier, 2023] \
[[Paper](https://www.sciencedirect.com/science/article/abs/pii/S0031320323002625)]

**Animation Line Art Colorization Based on Optical Flow Method** \
*Yifeng Yu, Jiangbo Qian, Chong Wang, Yihong Dong, Baisong Liu*\
[27 Aug., 2022] [SSNR, 2022] \
[[Paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4202289)]

**The Animation Transformer: Visual Correspondence via Segment Matching** \
*Evan Casey, VÃ­ctor PÃ©rez, Zhuoru Li, Harry Teitelman, Nick Boyajian, Tim Pulver, Mike Manh, William Grisaitis*\
[6 Sep., 2021] [arXiv, 2021] \
[[Paper](https://arxiv.org/abs/2109.02614)] | [[Demo](https://cadmium.app/)]

**Artist-Guided Semiautomatic Animation Colorization** \
*Harrish Thasarathan, Mehran Ebrahimi* \
[22 Jun., 2020] [arXiv, 2020] \
[[Paper](https://arxiv.org/abs/2006.13717)]

**Deep Line Art Video Colorization with a Few References** \
*Min Shi, Jia-Qi Zhang, Shu-Yu Chen, Lin Gao, Yu-Kun Lai, Fang-Lue Zhang* \
[24 Mar., 2020] [arXiv, 2020] \
[[Paper](https://arxiv.org/abs/2003.10685)]

**Line Art Correlation Matching Feature Transfer Network for Automatic Animation Colorization** \
*Zhang Qian, Wang Bo, Wen Wei, Li Hai, Liu Jun Hui* \
[14 Apr., 2020] [arXiv, 2020] \
[[Paper](https://arxiv.org/abs/2004.06718)]

**Automatic Temporally Coherent Video Colorization** \
*Harrish Thasarathan, Kamyar Nazeri, Mehran Ebrahimi* \
[21 Apr., 2019] [arXiv, 2019] \
[[Paper](https://arxiv.org/abs/1904.09527)] | [[project](https://github.com/Harry-Thasarathan/TCVC)]






## Inbetweening & Interpolation

**Deep Geometrized Cartoon Line Inbetweening** \
*Li Siyao, Tianpei Gu, Weiye Xiao, Henghui Ding, Ziwei Liu, Chen Change Loy*\
[Nov., 2023] [ICCV 2023] \
[[paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Siyao_Deep_Geometrized_Cartoon_Line_Inbetweening_ICCV_2023_paper.pdf)] | [[project](https://github.com/lisiyao21/AnimeInbet)] | [[dataset](https://github.com/lisiyao21/AnimeInbet)]

**Exploring inbetween charts with trajectory-guided sliders for cutout animation**
*T Fukusato, A Maejima, T Igarashi, T Yotsukura*\
[1 Sep., 2023] [MTA 2023] \
[[paper](https://link.springer.com/article/10.1007/s11042-023-17354-x)]

**Enhanced Deep Animation Video Interpolation** \
*Wang Shen, Cheng Ming, Wenbo Bao, Guangtao Zhai, Li Chen, Zhiyong Gao*\
[25 Jun., 2022] [arXiv, 2022] \
[[paper](https://arxiv.org/abs/2206.12657)]

**SketchBetween: Video-to-Video Synthesis for Sprite Animation via Sketches** \
*Dagmar Lukka LoftsdÃ³ttir, Matthew Guzdial*\
[1 Sep., 2022] [arXiv, 2022] \
[[paper](https://arxiv.org/abs/2209.00185)] | [[project](https://github.com/ribombee/SketchBetween)]

**Deep Animation Video Interpolation in the Wild** \
*Li Siyao, Shiyu Zhao, Weijiang Yu, Wenxiu Sun, Dimitris N. Metaxas, Chen Change Loy, Ziwei Liu*\
[6 Apr., 2021] [arXiv, 2021] \
[[paper](https://arxiv.org/abs/2104.02495)] | [[project](https://github.com/lisiyao21/AnimeInterp/)] | [[dataset](https://github.com/lisiyao21/AnimeInterp/)]

**Deep Sketch-guided Cartoon Video Inbetweening** \
*Xiaoyu Li, Bo Zhang, Jing Liao, Pedro V. Sander*\
[10 Aug., 2020] [arXiv, 2020] \
[[paper](https://arxiv.org/abs/2008.04149)]

**Optical Flow Based Line Drawing Frame Interpolation Using Distance Transform to Support Inbetweenings** \
*Rei Narita, Keigo Hirakawa, Kiyoharu Aizawa*\
[26 Aug., 2019] [IEEE, 2019] \
[[paper](https://ieeexplore.ieee.org/document/8803506)]

**DiLight: Digital light table â€“ Inbetweening for 2D animations using guidelines** \
*Leonardo Carvalho, Ricardo Marroquim, Emilio Vital Brazil*\
[Jun., 2017] [Elsevier, 2017] \
[[paper](https://www.sciencedirect.com/science/article/abs/pii/S0097849317300390)]


## How to Contribute
We encourage animation enthusiasts, researchers, and scholars to contribute to this repository by adding relevant papers, articles, and resources. Your contributions will help build a valuable reference for anyone interested in the art and science of animation.

To contribute, simply fork this repository, make your additions or improvements, and submit a pull request. Please follow the contribution guidelines outlined in the repository's README file.